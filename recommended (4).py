# -*- coding: utf-8 -*-
"""recommended.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A_bvQLj0FJX5vzch3d3gh1b4pqiGPch6

## **Importing the libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
from tabulate import tabulate
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

"""## **Importing the dataset**"""

 ###  drive.mount('/content/drive') //

data = pd.read_csv("ratings_Beauty.csv")

"""## **Inspecting and visualizing the dataset**

### General property of the dataset
"""

# Check the shape of the dataset
print("Dataset shape: ", data.shape)

# Look at the first few rows of the dataset
print("\nFirst few rows of the dataset: \n")
print(data.head())

# Remove rows with any null values
df_cleaned = data.dropna()

# Check for duplicate rows
duplicates = df_cleaned.duplicated(["UserId", "ProductId", "Rating", "Timestamp"]).sum()
print("Number of duplicated entries:", duplicates)

num_unique_users = df_cleaned["UserId"].nunique()
num_unique_products = df_cleaned["ProductId"].nunique()
num_total_ratings = df_cleaned.shape[0]

print("\nNumber of unique users:", num_unique_users)
print("Number of unique products:", num_unique_products)
print("Number of total ratings:", num_total_ratings)

summary_df = pd.DataFrame({
    "Category": ["Unique Users", "Unique Products", "Total Ratings"],
    "Count": [num_unique_users, num_unique_products, num_total_ratings]
})

plt.figure(figsize=(10, 5))
sns.barplot(x="Category", y="Count", data=summary_df, palette="coolwarm")

plt.xlabel("Category")
plt.ylabel("Count")
plt.title("Users, Products, and Ratings")
plt.xticks(rotation=0)
plt.show()

# Check if there are any null entries
print("Are there any null entries?\n")
print(df_cleaned.isnull().any())

"""### About the ratings"""

# Count number of ratings for each rating value
rating_counts = df_cleaned["Rating"].value_counts()

print("Number of ratings for each rating value:\n")
print(rating_counts)

# Plot the graph
plt.figure(figsize=(10, 5))
sns.barplot(x=rating_counts.index, y=rating_counts.values, palette="turbo")

# Add labels and title
plt.xlabel("Rating Value")
plt.ylabel("Number of Ratings")
plt.xticks(rotation=0)

# Show the plot
plt.show()

"""### About the users"""

# Number of ratings given by each user
rated_users = df_cleaned.groupby("UserId")["Rating"].count().sort_values(ascending = False)

print("Number of ratings given by each user:\n")
print(rated_users)

# Count number of ratings per user
top_users = df_cleaned['UserId'].value_counts().head(5)

top_users.index = top_users.index.astype(str)

# Plot the graph
plt.figure(figsize=(10, 5))
sns.barplot(x=top_users.index, y=top_users.values, hue=top_users.index,
            palette="viridis", legend=False)

plt.xlabel("User ID")
plt.ylabel("Number of Ratings")
plt.title("Top 5 Users who have given most ratings")
plt.xticks(rotation=0)

plt.show()

"""### About the products"""

# Number of ratings received by each product
rated_products = df_cleaned.groupby("ProductId")["Rating"].count().sort_values(ascending = False)

print("Number of ratings received by each product:\n")
print(rated_products)

import matplotlib.pyplot as plt
import seaborn as sns

top_rated_products = df_cleaned.groupby("ProductId")["Rating"].count().sort_values(ascending=False).head(5)

top_rated_products.index = top_rated_products.index.astype(str)

plt.figure(figsize=(10, 5))
sns.barplot(x=top_rated_products.index, y=top_rated_products.values,
            hue=top_rated_products.index, palette="magma", legend=False)

plt.xlabel("Product ID")
plt.ylabel("Number of Ratings")
plt.title("Top 5 Most Rated Products")
plt.xticks(rotation=0)

plt.show()

"""# Creating a Table which shows details about the **product**"""

# number of unique ratings for each product
unique_ratings_count = data.groupby('ProductId')['Rating'].count()

# average rating for each product
average_ratings = data.groupby('ProductId')['Rating'].mean()

product_summary = pd.DataFrame({
    'Number of User Ratings': unique_ratings_count,
    'Average Rating': average_ratings
})

product_summary = product_summary.sort_values(by='Number of User Ratings', ascending=False)

print(product_summary)

"""# Calculating and assigning a score for each product"""

unique_ratings_count = data.groupby('ProductId')['Rating'].count()
average_ratings = data.groupby('ProductId')['Rating'].mean()

# Total number of users in the dataset
total_users = data['UserId'].nunique()
print(total_users)


product_summary = pd.DataFrame({
    'Number of User Ratings': unique_ratings_count,
    'Average Rating': average_ratings
})


product_summary['Score'] = (
    product_summary['Number of User Ratings'] * product_summary['Average Rating']
) / total_users


product_summary = product_summary.sort_values(by='Score', ascending=False)

print(product_summary)

total_users = data['UserId'].nunique()

product_summary['Score'] = (
    product_summary['Number of User Ratings'].fillna(0) *
    product_summary['Average Rating'].fillna(0)
) / total_users

scaling_factor = 1_000_000

product_summary['Score'] = (product_summary['Score'] * scaling_factor).round().astype(int)

product_summary = product_summary.sort_values(by='Score', ascending=False)

print(product_summary)

# Filtering out products with a score less than 100
filtered_data = product_summary[product_summary['Score'] >= 100]

print(filtered_data)

print(tabulate(filtered_data.head(10), headers='keys', tablefmt='pretty'))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.barplot(x=filtered_data.head(10).index,
            y=filtered_data["Score"].head(10),
            palette="viridis")

plt.xlabel("Product ID")
plt.ylabel("Score")
plt.title("Top 10 Products by Score")
plt.xticks(rotation=45, ha='right')

plt.show()

"""# **Content-based Filtering using Cosine Similarity**"""

df = filtered_data.copy()

# Select relevant numerical features
df_features = df[['Number of User Ratings', 'Average Rating', 'Score']]

# Standardize the data
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features)

# Cosine Similarity
cosine_sim = cosine_similarity(df_scaled)

# Convert into a DataFrame with product IDs as index and columns
cosine_sim_df = pd.DataFrame(cosine_sim, index=df.index, columns=df.index)
print(cosine_sim_df)

"""# **Implementing Product Recommendation Function**"""

def recommend_products(top_n=5):
    product_id = input("Enter Product ID: ").strip()  # Get product ID as string input

    if product_id not in cosine_sim_df.index:
        return "Product not found!"

    # Get top-N similar products
    similar_products = cosine_sim_df[product_id].sort_values(ascending=False).iloc[1:top_n+1]

    # Convert to DataFrame for better formatting
    recommended_df = similar_products.reset_index()
    recommended_df.columns = ["Product ID", "Similarity Score"]

    # Print recommendations in table format
    print("\nContent-based Recommended Products:\n")
    print(tabulate(recommended_df, headers='keys', tablefmt='pretty'))

# Call the function and display recommendations
recommend_products()

"""# **Combining both tables using productid**"""

# Merge both tables using 'ProductId' as the common key
df_merged = pd.merge(data,filtered_data , on='ProductId', how='inner')
df_merged.drop(columns=['Timestamp'], inplace=True)

print(df_merged)

"""# **Details about the product**"""

df = df_merged[['UserId', 'ProductId', 'Rating']]

total_users = df['UserId'].nunique()

def get_product_details():

    product_id = input("Enter Product ID: ").strip()

    if product_id not in df['ProductId'].values:
        return "Product not found!"

    # Get users who rated the product and their ratings
    product_data = df[df['ProductId'] == product_id]

    # Extract users who rated this product
    users_who_rated = product_data[['UserId', 'Rating']].reset_index(drop=True)

    # Calculate the average rating of the product
    avg_rating = product_data['Rating'].mean()

    # Count number of ratings for this product
    num_ratings = len(product_data)

    # Compute product score using the given formula
    scaling_factor = 1_000_000
    product_score = int(((num_ratings * avg_rating) / total_users) * scaling_factor)

    print(f"\nðŸ”¹ Product ID: {product_id}")
    print(f"ðŸ”¹ Total Ratings: {num_ratings}")
    print(f"ðŸ”¹ Average Rating: {avg_rating:.2f}")
    print(f"ðŸ”¹ Product Score: {product_score}\n")
    print(f"ðŸ”¹ Users who rated this product:\n")
    print(users_who_rated.to_string(index=False))

get_product_details()

"""# **Collaborative Filtering**

# **Memory-based collaborative filtering**
"""

# Select relevant columns
df = df_merged[['UserId', 'ProductId', 'Rating']].copy()

# Convert to categorical data type
df['UserId'] = df['UserId'].astype('category')
df['ProductId'] = df['ProductId'].astype('category')

# Create a sparse User-Item matrix
user_item_sparse = csr_matrix(
    (df['Rating'].values, (df['UserId'].cat.codes.values, df['ProductId'].cat.codes.values))
)

# Compute Cosine Similarity between products
product_similarity = cosine_similarity(user_item_sparse.T)

# Convert similarity matrix into a DataFrame
product_ids = df['ProductId'].cat.categories  # Extract Product IDs
product_similarity_df = pd.DataFrame(product_similarity, index=product_ids, columns=product_ids)

def recommend_memory_based(top_n=5):
    """Recommend top-N similar products using Memory-Based Collaborative Filtering."""

    product_id = input("Enter Product ID: ").strip()

    if product_id not in product_similarity_df.index:
        return "Product not found!"

    # Get similarity scores for the given product
    similar_products = product_similarity_df[product_id].sort_values(ascending=False)

    # Return top-N similar products (excluding the input product itself)
    recommended_df = pd.DataFrame(similar_products.iloc[1:top_n+1]).reset_index()
    recommended_df.columns = ["Product ID", "Similarity Score"]

    return recommended_df

# Get Recommendations
recommended_products = recommend_memory_based()

# Display Recommendations in a Table Format
if isinstance(recommended_products, str):  # If "Product not found!" is returned
    print(recommended_products)
else:
    print("\nMemory-Based Recommended Products:")
    print(tabulate(recommended_products, headers='keys', tablefmt='pretty'))

"""# **Model-based collaborative filtering**"""

!pip install scikit-surprise

import pandas as pd
import numpy as np
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from tabulate import tabulate

# Set a fixed seed for reproducibility
np.random.seed(42)

# Load dataset
df = df_merged[['UserId', 'ProductId', 'Rating']]

# Define rating scale
reader = Reader(rating_scale=(1, 5))

# Load data into Surprise dataset format
data = Dataset.load_from_df(df[['UserId', 'ProductId', 'Rating']], reader)

# Split into training and testing sets
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Initialize and train the SVD model with fixed seed
svd = SVD(random_state=42)
svd.fit(trainset)

# Extract product latent factors from trained SVD model
product_factors = {trainset.to_raw_iid(iid): svd.qi[iid] for iid in trainset.all_items()}

# Convert to Pandas DataFrame
product_factors_df = pd.DataFrame(product_factors).T

# Build Nearest Neighbors model for fast lookups
nn_model = NearestNeighbors(n_neighbors=20, metric='cosine', algorithm='auto')
nn_model.fit(product_factors_df)

def recommend_model_based_fast(product_id, top_n=5):
    """Recommend top-N similar products using Precomputed Similarities + Nearest Neighbors."""

    if product_id not in product_factors:
        return "Product not found!"

    # Get product vector
    product_vector = product_factors[product_id].reshape(1, -1)

    # Find top-N similar products using Nearest Neighbors
    distances, indices = nn_model.kneighbors(product_vector, n_neighbors=top_n + 1)

    # Extract recommended product IDs
    recommended_products = product_factors_df.iloc[indices[0][1:]].index.tolist()
    similarity_scores = 1 - distances[0][1:]  # Convert cosine distances to similarity scores

    # Convert to DataFrame for better readability
    recommended_df = pd.DataFrame({'Product ID': recommended_products, 'Similarity Score': similarity_scores})

    return recommended_df

# Get product input
product_id = input("Enter Product ID: ").strip()
recommended_products = recommend_model_based_fast(product_id)

# Display recommendations
if isinstance(recommended_products, str):  # If "Product not found!" is returned
    print(recommended_products)
else:
    print("\nModel-Based Recommended Products:")
    print(tabulate(recommended_products, headers='keys', tablefmt='pretty'))

"""# **Hybrid**"""

import pandas as pd
import numpy as np
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from tabulate import tabulate

# Set seed for reproducibility
np.random.seed(42)

# Load dataset
df = df_merged[['UserId', 'ProductId', 'Rating']].copy()

# Content-Based Filtering (Feature Similarity)
df_features = df.groupby('ProductId').agg({'Rating': ['mean', 'count']}).reset_index()
df_features.columns = ['Product ID', 'Average Rating', 'Number of User Ratings']

# Standardize Features
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features[['Average Rating', 'Number of User Ratings']])

# Compute Cosine Similarity
cosine_sim = cosine_similarity(df_scaled)
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_features['Product ID'], columns=df_features['Product ID'])

# Memory-Based Filtering (User-Item Matrix)
df['UserId'] = df['UserId'].astype('category')
df['ProductId'] = df['ProductId'].astype('category')

user_item_sparse = csr_matrix(
    (df['Rating'].values, (df['UserId'].cat.codes.values, df['ProductId'].cat.codes.values))
)

product_similarity = cosine_similarity(user_item_sparse.T)
product_similarity_df = pd.DataFrame(product_similarity,
                                     index=df['ProductId'].cat.categories,
                                     columns=df['ProductId'].cat.categories)

# Model-Based Filtering (SVD + Nearest Neighbors)
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df[['UserId', 'ProductId', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

svd = SVD(random_state=42)
svd.fit(trainset)

product_factors = {trainset.to_raw_iid(iid): svd.qi[iid] for iid in trainset.all_items()}
product_factors_df = pd.DataFrame(product_factors).T

nn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='auto')
nn_model.fit(product_factors_df)

# Hybrid Recommendation Function
def recommend_hybrid(product_id, top_n=5, weights=(0.4, 0.3, 0.3)):
    """Combines Content-Based, Memory-Based, and Model-Based Filtering."""

    if product_id not in cosine_sim_df.index:
        return "Product not found!"

    # Content-Based Recommendations
    content_recs = cosine_sim_df.loc[product_id].sort_values(ascending=False).iloc[1:top_n+1]

    # Memory-Based Recommendations
    memory_recs = product_similarity_df.loc[product_id].sort_values(ascending=False).iloc[1:top_n+1]

    # Model-Based Recommendations
    product_vector = product_factors[product_id].reshape(1, -1)
    distances, indices = nn_model.kneighbors(product_vector, n_neighbors=top_n + 1)
    model_recs = pd.Series(1 - distances[0][1:], index=product_factors_df.iloc[indices[0][1:]].index)

    # Merge Recommendations
    recs_df = pd.DataFrame(index=content_recs.index.union(memory_recs.index).union(model_recs.index))

    recs_df['Content Score'] = content_recs
    recs_df['Memory Score'] = memory_recs
    recs_df['Model Score'] = model_recs

    # Normalize and Combine Scores
    recs_df.fillna(0, inplace=True)
    recs_df['Score'] = (
        weights[0] * recs_df['Content Score'] +
        weights[1] * recs_df['Memory Score'] +
        weights[2] * recs_df['Model Score']
    )

    # Select only the required columns
    recs_df = recs_df[['Score']].sort_values(by='Score', ascending=False).iloc[:top_n].reset_index()
    recs_df.columns = ["Product ID", "Score"]

    return recs_df

# Get Recommendations
product_id = input("Enter Product ID: ").strip()

recommended_products = recommend_hybrid(product_id)

# Display Recommendations
if isinstance(recommended_products, str):
    print(recommended_products)
else:
    print("\nHybrid Recommended Products:")
    print(tabulate(recommended_products, headers='keys', tablefmt='pretty'))

import pandas as pd
import numpy as np
from surprise import SVD, Dataset, Reader
from surprise.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from tabulate import tabulate

# Set seed for reproducibility
np.random.seed(42)

# Load dataset
df = df_merged[['UserId', 'ProductId', 'Rating']].copy()

# Content-Based Filtering (Feature Similarity)
df_features = df.groupby('ProductId').agg({'Rating': ['mean', 'count']}).reset_index()
df_features.columns = ['Product ID', 'Average Rating', 'Number of User Ratings']

# Standardize Features
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_features[['Average Rating', 'Number of User Ratings']])

# Compute Cosine Similarity
cosine_sim = cosine_similarity(df_scaled)
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_features['Product ID'], columns=df_features['Product ID'])

# Memory-Based Filtering (User-Item Matrix)
df['UserId'] = df['UserId'].astype('category')
df['ProductId'] = df['ProductId'].astype('category')

user_item_sparse = csr_matrix(
    (df['Rating'].values, (df['UserId'].cat.codes.values, df['ProductId'].cat.codes.values))
)

product_similarity = cosine_similarity(user_item_sparse.T)
product_similarity_df = pd.DataFrame(product_similarity,
                                     index=df['ProductId'].cat.categories,
                                     columns=df['ProductId'].cat.categories)

# Model-Based Filtering (SVD + Nearest Neighbors)
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df[['UserId', 'ProductId', 'Rating']], reader)
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

svd = SVD(random_state=42)
svd.fit(trainset)

product_factors = {trainset.to_raw_iid(iid): svd.qi[iid] for iid in trainset.all_items()}
product_factors_df = pd.DataFrame(product_factors).T

nn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='auto')
nn_model.fit(product_factors_df)

# Hybrid Recommendation Function
def recommend_hybrid(product_id, top_n=5, weights=(0.4, 0.3, 0.3)):
    """Generates hybrid recommendations for any given product ID."""

    if product_id not in cosine_sim_df.index:
        return "Product not found!"

    # Content-Based Recommendations
    content_recs = cosine_sim_df.loc[product_id].sort_values(ascending=False).iloc[1:top_n+1]
    content_recs = pd.DataFrame({"Product ID": content_recs.index, "Similarity Score": content_recs.values})

    # Memory-Based Recommendations
    memory_recs = product_similarity_df.loc[product_id].sort_values(ascending=False).iloc[1:top_n+1]
    memory_recs = pd.DataFrame({"Product ID": memory_recs.index, "Similarity Score": memory_recs.values})

    # Model-Based Recommendations
    product_vector = product_factors[product_id].reshape(1, -1)
    distances, indices = nn_model.kneighbors(product_vector, n_neighbors=top_n + 1)
    model_recs = pd.DataFrame({
        "Product ID": product_factors_df.iloc[indices[0][1:]].index,
        "Similarity Score": 1 - distances[0][1:]
    })

    print("\nContent-based Recommended Products:")
    print(tabulate(content_recs, headers='keys', tablefmt='pretty'))

    print("\nMemory-Based Recommended Products:")
    print(tabulate(memory_recs, headers='keys', tablefmt='pretty'))

    print("\nModel-Based Recommended Products:")
    print(tabulate(model_recs, headers='keys', tablefmt='pretty'))

# Get Recommendations
product_id = input("Enter Product ID: ").strip()
recommend_hybrid(product_id)